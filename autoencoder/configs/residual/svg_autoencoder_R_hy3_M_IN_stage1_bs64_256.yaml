# Main training configuration - Using original target
training:
  logdir: "logs"
  scale_lr: false
  accumulate_grad_batches: 1
  save_every_n_train_steps: 20000
  save_every_n_epochs: 1

  trainer:
    devices: 8
    num_nodes: 1
    strategy: "ddp_find_unused_parameters_true"
    accelerator: "gpu"
    max_epochs: 1000
    precision: 32
  
  
# Model configuration
model:
  init_weight: null
  base_learning_rate: 1.0e-04
  target: ldm.models.dinov3_decoder_imagenet.DinoDecoder
  params:    
    ckpt_path: null
    embed_dim: 32
    lossconfig:
      target: "ldm.modules.losses.LPIPSWithDiscriminatorDecoderIN"
      params:
        disc_start: 5000
        disc_weight: 0.5
    
    ddconfig: null
    hyconfig:
      block_out_channels: [768, 384, 192, 192, 96]
      out_channels: 3
      z_channels: 392
      num_res_blocks: 2
      ffactor_spatial: 16
      ffactor_temporal: 1
      upsample_match_channel: true

    dinoconfig:
      dinov3_location: dinov3 # change here
      model_name: dinov3_vits16plus
      weights: dinov3_vits16plus_pretrain_lvd1689m-4057cbaa.pth
    extra_vit_config: 
      output_dim: 8
      mask_ratio: 0.0
      use_outnorm: true
      vit_type: vit-rope-s


# Data configuration
data:
  target: "utils.data_module_allinone.DataModuleFromConfig"
  params:
    batch_size: 64
    wrap: true
    num_workers: 16
    use_worker_init_fn: true
    shuffle_val_dataloader: false
    
    train:
      target: ldm.data.imagenet.ImageNetTrain
      params:
        data_root: YourPath
        size: 256

    validation:
      target: ldm.data.imagenet.ImageNetValidation
      params:
        data_root: YourPath
        size: 256